\section{Modélisation du risque de défaut}

\subsection{Les modèles à intensité}

L'intuition générale des modèles à intensité est basée sur la décomposition de Doob-Meyer
qui assure l'existence d'une décomposition unique du processus de défaut $H$ défini section
\ref{subsubsection:espace_prob_filtre} de la forme $H_t = M_t + A_t$ où $M_t$ est une
$\mathbb{G}$-martingale et $A_t$ est un processus $\mathbb{G}$-prévisible croissant. Cette propriété
est à l'origine de l'hypothèse selon laquelle il existe un unique processus
$(\lambda_t)_{t \ge 0}$ $\mathbb{F}$-adapté appelé intensité de défaut tel que le processus
$M_t$ défini comme
\begin{equation}
    M_t := H_t - \int_0^t \mathbb{1}_{ \{ u \le \tau \} } \lambda_u \, du
\end{equation}
soit une $\mathbb{G}$-martingale. \cite{defaut_intensite}

A présent prenons $0 \le t \le T$, par la propriété de martingale en prenant l'espérance
conditionnelle $ \mathbb{E}[M_T - M_t \mid \mathcal{G}_t] = 0 $, donc
\begin{equation}
    \mathbb{E}[H_T - H_t \mid \mathcal{G}_t] = \mathbb{E}\left[ \int_t^T \mathbb{1}_{ \{ u \le \tau \} } \lambda_u \, du \, \middle| \, \mathcal{G}_t \right]
\end{equation}
Or $ H_T - H_t = \mathbb{1}_{ \{ t < \tau \le T \} } $ donc
\begin{equation}
    \mathbb{E}[H_T - H_t \mid \mathcal{G}_t] = \mathbb{P}( t < \tau \le T \mid \mathcal{G}_t)
\end{equation}
Et par positivité de l'intégrande et par hypothèse que $\lambda$ est $\mathbb{F}$-adapté, en utilisant le théorème de Fubini
\begin{equation}
    \mathbb{E}\left[ \int_t^T \mathbb{1}_{ \{ u < \tau \} } \lambda_u \, du \, \middle| \, \mathcal{G}_t \right]
    = \int_t^T \lambda_u \mathbb{E}\left[ \mathbb{1}_{ \{ u < \tau \} } \, \middle| \, \mathcal{G}_t  \right]  du 
\end{equation}
Or pour $u \ge t $, nous avons $ \mathbb{1}_{ \{ u < \tau \} } = \mathbb{1}_{ \{ \tau > t \} }\mathbb{1}_{ \{ \tau > u \} }$ et comme
$ \{ \tau > t \} \in \mathcal{G}_t$ :
\begin{equation}
    \mathbb{E}\left[ \mathbb{1}_{ \{ u < \tau \} } \, \middle| \, \mathcal{G}_t  \right] = \mathbb{1}_{ \{ \tau > t \} } \mathbb{P}( \tau > u \mid \mathcal{F}_t)
\end{equation}  
Nous obtenons l'égalité
\begin{equation}
    \mathbb{P}( t < \tau \le T \mid \mathcal{G}_t)
    = \mathbb{1}_{ \{ \tau > t \} } \int_t^T \lambda_u \mathbb{P}( \tau > u \mid \mathcal{F}_t)  du 
\end{equation}
Or en remarquant qu'aucune information lié à $\{ \tau > T \}$ n'est dans $\mathcal{H}_t = \sigma(\{\tau \leq s\} : s \leq t)$ nous pouvons établir un dernier résultat : 
\begin{align*}
    \mathbb{P}( t < \tau \le T \mid \mathcal{G}_t) & = \mathbb{E}[ \mathbb{1}_{\{t < \tau \le T\}} \mid \mathcal{G}_t ] \\
    & = \mathbb{E}[ \mathbb{1}_{\{t < \tau \}} \mathbb{1}_{\{ \tau \le T\}} \mid \mathcal{G}_t ] \\
    & = \mathbb{1}_{\{t < \tau \}} \mathbb{E}[\mathbb{1}_{\{ \tau \le T\}} \mid \mathcal{G}_t ] \\
    & = \mathbb{1}_{\{t < \tau \}} (1 - \mathbb{E}[\mathbb{1}_{\{ \tau > T\}} \mid \mathcal{G}_t ]) \\
    & = \mathbb{1}_{\{t < \tau \}} (1 - \mathbb{E}[\mathbb{1}_{\{ \tau > T\}} \mid \mathcal{F}_t ]) \\
    & = \mathbb{1}_{\{t < \tau \}} (1 - \mathbb{P}( \tau > T \mid \mathcal{F}_t ))
\end{align*}
Finalement en posant $f(t, u) = \mathbb{P}(\tau > u \mid \mathcal{F}_t)$, nous obtenons l'équation suivante :
\begin{equation}
    1 - f(t,T) = \int_t^T \lambda_u \, f(t,u) \, du 
\end{equation}
Et en dérivant l'équation précédente nous obtenons le problème de Cauchy :
\begin{equation}
    \begin{cases}
        \partial_u f(t,u) = - \lambda_u f(t,u) \\
        f(t,t) = 1
    \end{cases}
\end{equation}
La solution de ce problème est donnée par :
\begin{equation}\label{eq:poisson_jump}
    \mathbb{P}(\tau > T \mid \mathcal{F}_t) = \exp\left(- \int_t^T \lambda_u \, du \right), \quad \text{p.s.}
\end{equation}
Nous reconnaissons la probabilité qu'il n'y ait aucun saut pendant un intervalle de temps $T-t$ sur le
processus de Poisson non homogène $H$ d'intensité stochastique $\lambda$.

\subsection{Modélisation du risque d'un CDS}

La détermination du prix d'un Credit Default Swap repose sur la modélisation 
probabiliste du temps de défaut de l'entité de référence. L'objectif de cette section 
est d'établir le cadre théorique permettant de dériver la loi de probabilité du temps 
de défaut, afin de calculer le spread équitable du contrat.

Considérons un CDS de maturité $T$ portant sur un notionnel $N$, avec un taux de 
recouvrement $R$ et un spread $s$. Le spread de marché équitable est determiné grâce
à l'égalité entre la valeur actualisée de la jambe premium \eqref{premium_leg} 
et celle de la jambe protection \eqref{protection_leg}. Pour modéliser le temps de défaut, nous reprenons le résultat (\ref{eq:poisson_jump})
et prenons l'espérance risque-neutre sur $\mathcal{F}_t$ il est possible d'écrire :
\begin{equation}
\mathbb{P}^*(\tau > t) = \mathbb{E}^{\mathbb{P}^\ast}
\!\left[ \exp\left(-\int_0^t \lambda(s) \, ds\right) \right].
\end{equation}
Lorsque l'intensité est déterministe, $\lambda(t) : \mathbb{R}_+ \to \mathbb{R}_+$, 
la probabilité de survie devient
\begin{equation}
\mathbb{P}^*(\tau > t) = \exp\left(-\int_0^t \lambda(s) \, ds\right).
\end{equation}
Les valeurs actualisées des jambes \eqref{premium_leg} et \eqref{protection_leg} 
peuvent alors être calculées semi-analytiquement. Le cas particulier d'une intensité 
constante $\lambda(t) = \lambda$ conduit à une loi exponentielle 
$\mathbb{P}^*(\tau > t) = e^{-\lambda t}$ et en effectuant l'hypothèse d'un taux constant
$r_t=r$ il est possible d'obtenir une expression analytique pour le spread. En effet,
considérons que la prime est payée jusqu'au défaut, la jambe fixe s'écrit alors
\begin{equation}
    \begin{split}
        \text{JF}(s) &
        = s\,N \sum_{k=1}^m \delta_k \; \mathbb{E}^{\mathbb{P}^\ast} \!\left[\frac{\mathbb{1}_{\{\tau > T_k\}}}{B_{T_k}}\right] \\
        & = s\,N \sum_{k=1}^m \delta_k \; e^{-(r + \lambda)T_{i+1}} \\
        & \approx s\,N \int_0^T e^{-(r + \lambda)u} du \\
        & = s\,N \frac{1 - e^{-(r + \lambda)T}}{r + \lambda}
    \end{split}
\end{equation}
De la même manière la jambe variable s'écrit
\begin{equation}
    \begin{split}
        \text{JV} &
        = N(1-R)\,\mathbb{E}^{\mathbb{P}^\ast} \!\left[\frac{\mathbb{1}_{\{\tau \le T\}}}{B_\tau}\right] \\
        & = N(1-R)\, \int_0^T \lambda e^{ - (r + \lambda)u} du \\
        & = N(1-R)\, \frac{\lambda}{r + \lambda} \left( 1 - e^{ - (r + \lambda)T} \right)
    \end{split}
\end{equation}
En égalisant les deux termes nous obtenons le \emph{fair spread} qui satisfait \emph{l'égalité du triangle}
\begin{equation}
    s^\ast = (1 - R) \lambda
\end{equation}

En pratique, il existe deux manière de procéder pour calibrer le modèle à intensité : soit en utilisant les
spreads de marché des CDS pour en déduire l'intensité de défaut, soit en modélisant directement l'intensité
comme un processus stochastique et en calibrant ses paramètres à partir de données historiques ou de prix
de marché. Dans le premier cas, la probabilité de défaut est alors sous la mesure risque neutre, tandis que
dans le second nous travaillons sous la mesure historique.

\subsection{Défauts corrélés}

\subsubsection{Modèles de copules}

La valorisation des tranches de CDO synthétiques requiert la modélisation de la 
distribution jointe des temps de défaut $\tau_1, \tau_2, \ldots, \tau_n$ du 
portefeuille. Les distributions marginales $F_i(t) = \mathbb{P}^*(\tau_i \leq t)$ 
étant connues, il reste à spécifier la structure de dépendance. Le théorème de Sklar stipule qu'il existe une fonction de copule $C : [0,1]^n \to [0,1]$ 
telle que
\begin{equation}
F(\tau_1, \tau_2, \ldots, \tau_n) = C(F_1(\tau_1), F_2(\tau_2), \ldots, F_n(\tau_n)).
\end{equation}
La copule $C$ encode la structure de dépendance indépendamment des marginales.

\paragraph{Copule gaussienne.}

La copule gaussienne suppose que les variables $\Phi^{-1}(F_i(\tau_i))$ suivent une loi 
normale multivariée de matrice de corrélation $\Sigma$, où $\Phi$ désigne la fonction 
de répartition de la loi normale centrée réduite. Elle s'écrit
\begin{equation}
C_{\Sigma}^{\text{Gauss}}(u_1, \ldots, u_n) 
= \Phi_{\Sigma}(\Phi^{-1}(u_1), \ldots, \Phi^{-1}(u_n)),
\end{equation}
avec $\Phi_{\Sigma}$ la fonction de répartition de $\mathcal{N}(0, \Sigma)$. En pratique,
on impose souvent une corrélation uniforme $\rho$ entre toutes les paires d'entités, 
réduisant le nombre de paramètres à un seul. L'absence de formule analytique pour la distribution des pertes nécessite une 
simulation Monte Carlo. L'algorithme génère un vecteur $\mathbf{Z} 
= (Z_1, \ldots, Z_n) \sim \mathcal{N}(0, \Sigma)$, puis applique les transformations
\begin{equation}
U_i = \Phi_{\Sigma}(Z_i), \quad \tau_i = F_i^{-1}(U_i),
\end{equation}
pour obtenir des scénarios de défaut corrélés permettant d'estimer les prix par moyenne 
empirique.

\paragraph{La copule de Student.}

Une extension importante de la copule gaussienne est la copule de Student, qui s'écrit
\begin{equation}
C_{\Sigma,\nu}^{t}(u_1, \ldots, u_n) 
= t_{\Sigma,\nu}(t_{\nu}^{-1}(u_1), \ldots, t_{\nu}^{-1}(u_n)),
\end{equation}
où $t_{\nu}$ désigne la fonction de répartition de la loi de Student univariée à $\nu$ 
degrés de liberté, et $t_{\Sigma,\nu}$ celle de la loi de Student multivariée. Le 
paramètre $\nu$ contrôle l'épaisseur des queues de distribution : plus $\nu$ est faible, 
plus les queues sont épaisses, capturant ainsi une dépendance extrême plus forte entre 
les défauts. Lorsque $\nu \to \infty$, la copule de Student converge vers la copule 
gaussienne. Cette propriété permet de mieux modéliser les défauts simultanés observés 
lors des périodes de stress financier, où la copule gaussienne tend à sous-estimer les 
événements de queue. La simulation numérique de la copule de Student est analogue à la
méthode précédente.



\subsubsection{Modèles à intensité stochastique}

Les modèles de copules présentent plusieurs limitations : structure de dépendance 
statique, absence de facteurs économiques explicites, et sous-estimation de la 
dépendance de queue. Une approche alternative décompose l'intensité de défaut de 
chaque entité $i$ en
\begin{equation}
\lambda_i(t) = \lambda_i^{\text{idio}}(t) + \beta_i \lambda^{\text{syst}}(t),
\end{equation}
où $\lambda_i^{\text{idio}}(t)$ est la composante idiosyncratique, 
$\lambda^{\text{syst}}(t)$ le facteur systémique commun, et $\beta_i \geq 0$ la 
sensibilité au risque systémique.

Les intensités sont modélisées par des processus stochastiques. Pour capturer les chocs 
macroéconomiques brutaux et les variations discontinues du risque de crédit, nous 
utilisons un processus de diffusion avec sauts pour le facteur systémique :
\begin{equation}\label{eq:lambda_syst}
d\lambda^{\text{syst}}(t) = \kappa(\theta - \lambda^{\text{syst}}(t)) \, dt + \sigma \sqrt{\lambda^{\text{syst}}(t)} \, dW(t) + dJ(t),
\end{equation}
où $\kappa > 0$ est la vitesse de retour à la moyenne, $\theta > 0$ le niveau de long 
terme, $\sigma > 0$ la volatilité, $W(t)$ un mouvement brownien, et $J(t)$ un processus 
de Poisson composé modélisant les sauts. Le processus de sauts s'écrit
\begin{equation}
J(t) = \sum_{i=1}^{P(t)} Y_i,
\end{equation}
où $P(t)$ est un processus de Poisson d'intensité $\ell$ et les $Y_i \sim \text{Exp}\left(\frac{1}{\mu}\right)$ sont des 
variables aléatoires i.i.d. représentant l'amplitude des sauts. Cette spécification 
permet de capturer à la fois la dynamique continue du risque via la composante 
diffusion et les événements de crise via les sauts. On appelle un processus de cette
forme (\ref{eq:lambda_syst}) un processus basique affine de paramètre $(\kappa, \theta, \sigma
, \mu, \ell)$. \cite{DuffieGarleanu}

La corrélation entre défauts émerge naturellement via le facteur commun 
$\lambda^{\text{syst}}(t)$ : lorsque le risque systémique s'élève, toutes les 
intensités augmentent simultanément, générant une dépendance dynamique et capturant la 
dépendance de queue observée empiriquement. Les coefficients présentés précédemment peuvent alors
être ajustés afin d'approcher au mieux les observations empiriques. Des travaux ont été
réalisés afin de trouver des valeurs convenables pour les coefficients
$(\kappa, \theta, \sigma, \mu, \ell)$ ainsi que des incertitudes sur ceux-ci, des tables
de valeurs peuvent être trouvées dans Duffie et Gârleanu (1999).

La difficulté réelle de ces modèles réside dans la méconnaissance des intensités de défaut
idiosyncratiques propres mais également des coefficients de sensibilité au risque systémique.
Une première approximation par classe peut-être réalisée en regroupant les différents actifs
et en leur attribuant des intensités et sensibilités par groupes (par notation de crédit par exemple). 
Cependant ceci exige une analyse statistique historique fine de ces classes qui n'est pas toujours
possible. De plus, l'appartenance a une classe n'est pas nécessairement définitive, en effet il existe 
des modèles markoviens de transitions de classes permettant de prendre en compte des probabilités de
changement d'état des différents sous-jacents du portefeuille.
